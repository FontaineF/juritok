{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparation des corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ID texte            ID article  Nature N° article  \\\n",
      "0       JORFTEXT000048734585                   NaN       0        NaN   \n",
      "1       JORFTEXT000048734585  JORFVERS000048734585       0        NaN   \n",
      "2       JORFTEXT000048734585  JORFARTI000048734586       1          1   \n",
      "3       JORFTEXT000048734585  JORFARTI000048734586       1          1   \n",
      "4       JORFTEXT000048734585  JORFARTI000048734586       1          1   \n",
      "...                      ...                   ...     ...        ...   \n",
      "454296  JORFTEXT000046851183  JORFVERS000046851183       0        NaN   \n",
      "454297  JORFTEXT000046851183  JORFARTI000046851184       1        NaN   \n",
      "454298  JORFTEXT000046851186                   NaN       0        NaN   \n",
      "454299  JORFTEXT000046851186  JORFVERS000046851186       0        NaN   \n",
      "454300  JORFTEXT000046851186  JORFARTI000046851187       1        NaN   \n",
      "\n",
      "        N° alinéa                                            Contenu  \n",
      "0               0                     fr/lr/loi/2023-1380/2023-12-31  \n",
      "1               0  LOI n° 2023-1380 du 30 décembre 2023 visant à ...  \n",
      "2               1  I. — Après l'article L. 2122-19 du code généra...  \n",
      "3               2  « Art. L. 2122-19-1. — Pour assurer les foncti...  \n",
      "4               3  II. — L'article L. 2122-19-1 du code général d...  \n",
      "...           ...                                                ...  \n",
      "454296          0  Arrêté du 30 décembre 2022 portant admission à...  \n",
      "454297          1  Par arrêté du garde des sceaux, ministre de la...  \n",
      "454298          0               fr/lr/arrete/TREL2234954A/2023-01-01  \n",
      "454299          0  Arrêté du 22 décembre 2022 portant nomination ...  \n",
      "454300          1  Par arrêté du ministre de la transition écolog...  \n",
      "\n",
      "[454301 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "\n",
    "# Spécifiez le chemin vers votre fichier CSV\n",
    "chemin_fichier_csv = 'data/jorf_2023.csv'\n",
    "\n",
    "# Spécifiez le séparateur (dans ce cas, '|')\n",
    "separateur = '|'\n",
    "\n",
    "# Utilisez Pandas pour lire le fichier CSV dans un DataFrame\n",
    "df = pd.read_csv(chemin_fichier_csv, sep=separateur,names=[\"ID texte\",\"ID article\",\"Nature\",\"N° article\",\"N° alinéa\",\"Contenu\"])\n",
    "\n",
    "# Affichez le DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte extrait : de texte «à extraire» avec des guillemets «pour tester»».\n",
      "Texte extrait : Ceci est un exemple \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extraire_texte_entre_symboles(texte):\n",
    "    # Utilisez une expression régulière pour extraire le texte entre '«' et '»'\n",
    "    #match = re.search(r'«(.+)»', texte)\n",
    "    match = re.search(r'«(.+)', texte) # Beaucoup de phrases n'ont pas le '»' nécessaire\n",
    "    \n",
    "    # Vérifiez si une correspondance a été trouvée\n",
    "    if match:\n",
    "        texte_extrait = match.group(1)\n",
    "        return texte_extrait\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extraire_texte_en_dehors_des_symboles(texte):\n",
    "    # Utilisez une expression régulière pour extraire le texte entre '«' et '»'\n",
    "    match = re.search(r'^[^«]+', texte)\n",
    "    \n",
    "    # Vérifiez si une correspondance a été trouvée\n",
    "    if match:\n",
    "        texte_extrait = match.group(0)\n",
    "        return texte_extrait\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Exemple d'utilisation\n",
    "ma_chaine = \"Ceci est un exemple «de texte «à extraire» avec des guillemets «pour tester»».\"\n",
    "resultat = extraire_texte_entre_symboles(ma_chaine)\n",
    "\n",
    "if resultat:\n",
    "    print(\"Texte extrait :\", resultat)\n",
    "else:\n",
    "    print(\"Aucun texte trouvé entre les symboles '«' et '»'.\")\n",
    "    \n",
    "resultat = extraire_texte_en_dehors_des_symboles(ma_chaine)\n",
    "\n",
    "if resultat:\n",
    "    print(\"Texte extrait :\", resultat)\n",
    "else:\n",
    "    print(\"Aucun texte trouvé en dehors des symboles '«' et '»'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des colonnes ne contenant que les textes relatifs au Droit/non Droit\n",
    "df['droit'] = df['Contenu'].apply(extraire_texte_entre_symboles)\n",
    "df['non_droit'] = df['Contenu'].apply(extraire_texte_en_dehors_des_symboles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrire l'ensemble du contenu dans un fichier texte\n",
    "with open(\"input_data/jorf_2023.txt\",\"w\") as f:\n",
    "    f.writelines(\"\\n\".join(df[\"Contenu\"].to_list()))\n",
    "    \n",
    "# On extrait que le Droit : entre guillemets\n",
    "with open(\"./input_data/jorf_2023_droit.txt\",\"w\") as f:\n",
    "    data = \"\\n\".join(df[\"droit\"].dropna().to_list())\n",
    "    f.writelines(data)\n",
    "    \n",
    "# On extrait que ce qui entoure le Droit\n",
    "with open(\"./input_data/jorf_2023_non_droit.txt\",\"w\") as f:\n",
    "    data = \"\\n\".join(df[\"non_droit\"].dropna().to_list())\n",
    "    f.writelines(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A. Nombre de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in (100,1000,10000):\n",
    "    spm.SentencePieceTrainer.train(input='./input_data/jorf_2023.txt', model_prefix=f'./models/{n}_tokens', vocab_size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec 100 tokens :\n",
      "['▁', 'D', 'é', 'c', 're', 't', '▁d', 'u', '▁', '2', '9', '▁d', 'é', 'c', 'e', 'm', 'b', 're', '▁', '2', '0', '2', '3', '▁', 'p', 'o', 'r', 't', 'a', 'n', 't', '▁', 'p', 'r', 'o', 'm', 'o', 't', 'i', 'o', 'n', '▁d', 'a', 'n', 's', '▁', 'l', \"'\", 'o', 'r', 'd', 're', '▁', 'n', 'a', 't', 'i', 'o', 'n', 'a', 'l', '▁de', '▁', 'l', 'a', '▁', 'L', 'é', 'g', 'i', 'o', 'n', '▁d', \"'\", 'h', 'o', 'n', 'n', 'e', 'u', 'r']\n",
      "Avec 1000 tokens :\n",
      "['▁Décret', '▁du', '▁2', '9', '▁décembre', '▁2023', '▁portant', '▁pro', 'mo', 'tion', '▁dans', '▁l', \"'\", 'ord', 're', '▁national', '▁de', '▁la', '▁L', 'é', 'g', 'ion', '▁d', \"'\", 'h', 'onne', 'ur']\n",
      "Avec 10000 tokens :\n",
      "['▁Décret', '▁du', '▁29', '▁décembre', '▁2023', '▁portant', '▁promotion', '▁dans', '▁l', \"'\", 'ordre', '▁national', '▁de', '▁la', '▁Légion', '▁d', \"'\", 'honneur']\n"
     ]
    }
   ],
   "source": [
    "# On encode une phrase selon les différents modèles : 100 tokens appara^t clairement insuffisant\n",
    "for n in [100,1000,10000]:\n",
    "    sp = spm.SentencePieceProcessor(model_file=f'./models/{n}_tokens.model')\n",
    "    print(f\"Avec {n} tokens :\")\n",
    "    print(sp.EncodeAsPieces(\"Décret du 29 décembre 2023 portant promotion dans l'ordre national de la Légion d'honneur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 tokens sont bien sur insuffisants pour intélligement traiter ce lexique. Avec 1000 tokens on a encore quelques mots qu'on s'attendrait à voir pris dans l'intégralité et pourtant découpés, comme 'Légion' et 'honneur'. Avec 10000 tokens, la tokénisation est presque trop ample, en prenant '29' comme un token en soit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    B. Droit/non droit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.train(input='./input_data/jorf_2023_droit.txt', model_prefix='./models/droit', vocab_size=1000)\n",
    "spm.SentencePieceTrainer.train(input='./input_data/jorf_2023_non_droit.txt', model_prefix='./models/non_droit', vocab_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "« L'exonération est attribuée ou retirée dans les conditions prévues aux articles R. 5553-1 et R. 5553-2. »\n",
      "['▁«', '▁L', \"'\", 'ex', 'on', 'é', 'r', 'ation', '▁est', '▁', 'att', 'ri', 'b', 'u', 'ée', '▁ou', '▁re', 'ti', 'ré', 'e', '▁dans', '▁les', '▁conditions', '▁prévues', '▁aux', '▁articles', '▁R', '.', '▁5', '5', '5', '3-1', '▁et', '▁R', '.', '▁5', '5', '5', '3', '-2', '.', '▁»']\n",
      "['▁', '«', '▁L', \"'\", 'ex', 'on', 'é', 'r', 'ation', '▁est', '▁', 'at', 't', 'ri', 'b', 'u', 'ée', '▁ou', '▁re', 'ti', 'ré', 'e', '▁dans', '▁les', '▁conditions', '▁prévu', 'es', '▁aux', '▁articles', '▁R', '.', '▁5', '5', '5', '3', '-1', '▁et', '▁R', '.', '▁5', '5', '5', '3', '-', '2', '.', '▁', '»']\n",
      "\n",
      "\n",
      "Arrêté du 26 décembre 2023 relatif aux prix des prestations d'hébergement de certains établissements accueillant des personnes âgées\n",
      "['▁A', 'r', 'r', 'ê', 'té', '▁du', '▁2', '6', '▁décembre', '▁2023', '▁relatif', '▁aux', '▁p', 'ri', 'x', '▁des', '▁prestation', 's', '▁d', \"'\", 'h', 'é', 'b', 'er', 'g', 'ement', '▁de', '▁c', 'er', 't', 'ain', 's', '▁établissements', '▁', 'accueil', 'l', 'ant', '▁des', '▁personnes', '▁', 'â', 'g', 'ées']\n",
      "['▁Arrêté', '▁du', '▁', '26', '▁décembre', '▁2023', '▁relatif', '▁aux', '▁', 'pr', 'ix', '▁des', '▁', 'pr', 'est', 'ation', 's', '▁d', \"'\", 'h', 'é', 'b', 'er', 'g', 'ement', '▁de', '▁certain', 's', '▁', 'établissement', 's', '▁', 'accueil', 'l', 'ant', '▁des', '▁personne', 's', '▁', 'â', 'g', 'ées']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sp1 = spm.SentencePieceProcessor(model_file=f'./models/droit.model')\n",
    "sp2 = spm.SentencePieceProcessor(model_file=f'./models/non_droit.model')\n",
    "\n",
    "# Comparaison de la tokenisation d'une phrase de droit et d'une non de Droit \n",
    "s1 = \"« L'exonération est attribuée ou retirée dans les conditions prévues aux articles R. 5553-1 et R. 5553-2. »\"\n",
    "s2 = \"Arrêté du 26 décembre 2023 relatif aux prix des prestations d'hébergement de certains établissements accueillant des personnes âgées\"\n",
    "\n",
    "for s in [s1,s2]:\n",
    "    print(s)\n",
    "    for sp in [sp1,sp2]:\n",
    "        print(sp.EncodeAsPieces(s))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tokenisations Droit/Non Droit ont chacune adopté des tokens adaptés à leur vocabuaire, comme par exemple 'attribué'/'Arrêté'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    C. Avec un plus grand corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ID texte            ID article  Nature N° article  \\\n",
      "0        JORFTEXT000039696471                   NaN       0        NaN   \n",
      "1        JORFTEXT000039696471  JORFVERS000039696471       0        NaN   \n",
      "2        JORFTEXT000039696471  JORFARTI000039696480       1          1   \n",
      "3        JORFTEXT000039696471  JORFARTI000039696482       1          2   \n",
      "4        JORFTEXT000039696471  JORFARTI000039696482       1          2   \n",
      "...                       ...                   ...     ...        ...   \n",
      "2244515  JORFTEXT000046851183  JORFVERS000046851183       0        NaN   \n",
      "2244516  JORFTEXT000046851183  JORFARTI000046851184       1        NaN   \n",
      "2244517  JORFTEXT000046851186                   NaN       0        NaN   \n",
      "2244518  JORFTEXT000046851186  JORFVERS000046851186       0        NaN   \n",
      "2244519  JORFTEXT000046851186  JORFARTI000046851187       1        NaN   \n",
      "\n",
      "         N° alinéa                                            Contenu  \n",
      "0                0                  fr/lr/decret/2019-1501/2019-12-31  \n",
      "1                0  Décret n° 2019-1501 du 30 décembre 2019 relati...  \n",
      "2                1  L'allocation mentionnée à l'article R. 245-3 d...  \n",
      "3                1  Le code de l'action sociale et des familles es...  \n",
      "4                2  1° Il est inséré après l'article R. 146-25, un...  \n",
      "...            ...                                                ...  \n",
      "2244515          0  Arrêté du 30 décembre 2022 portant admission à...  \n",
      "2244516          1  Par arrêté du garde des sceaux, ministre de la...  \n",
      "2244517          0               fr/lr/arrete/TREL2234954A/2023-01-01  \n",
      "2244518          0  Arrêté du 22 décembre 2022 portant nomination ...  \n",
      "2244519          1  Par arrêté du ministre de la transition écolog...  \n",
      "\n",
      "[2244520 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Chemin vers le dossier contenant les fichiers CSV\n",
    "dossier_csv = 'data/'\n",
    "\n",
    "# Utiliser la fonction glob pour obtenir la liste des fichiers CSV dans le dossier\n",
    "fichiers_csv = glob.glob(dossier_csv + '*.csv')\n",
    "\n",
    "# Initialiser une liste pour stocker les DataFrames individuels\n",
    "dfs = []\n",
    "\n",
    "# Spécifiez le séparateur (dans ce cas, '|')\n",
    "separateur = '|'\n",
    "\n",
    "# Lire chaque fichier CSV et l'ajouter à la liste\n",
    "for fichier_csv in fichiers_csv:\n",
    "    df = pd.read_csv(fichier_csv,sep=separateur,names=[\"ID texte\",\"ID article\",\"Nature\",\"N° article\",\"N° alinéa\",\"Contenu\"])\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concaténer les DataFrames de la liste en un seul DataFrame\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Afficher le DataFrame final\n",
    "print(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des colonnes ne contenant que les textes relatifs au Droit/non Droit\n",
    "df_final['droit'] = df_final['Contenu'].apply(extraire_texte_entre_symboles)\n",
    "df_final['non_droit'] = df_final['Contenu'].apply(extraire_texte_en_dehors_des_symboles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2244520"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final[\"Contenu\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrire l'ensemble du contenu dans un fichier texte\n",
    "with open(\"input_data/jorf_2019_2023.txt\",\"w\") as f:\n",
    "    f.writelines(\"\\n\".join(df_final[\"Contenu\"].to_list()))\n",
    "    \n",
    "# On extrait que le Droit : entre guillemets\n",
    "with open(\"./input_data/jorf_2019_2023_droit.txt\",\"w\") as f:\n",
    "    data = \"\\n\".join(df_final[\"droit\"].dropna().to_list())\n",
    "    f.writelines(data)\n",
    "    \n",
    "# On extrait que ce qui entoure le Droit\n",
    "with open(\"./input_data/jorf_2019_2023_non_droit.txt\",\"w\") as f:\n",
    "    data = \"\\n\".join(df_final[\"non_droit\"].dropna().to_list())\n",
    "    f.writelines(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spm.SentencePieceTrainer.train(input='./input_data/jorf_2019_2023.txt', model_prefix='./models/2019_2023', vocab_size=1000)\n",
    "spm.SentencePieceTrainer.train(input='./input_data/jorf_2019_2023.txt', model_prefix='./models/2019_2023', vocab_size=1000,shuffle_input_sentence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec le corpus 2023 :\n",
      "['▁Décret', '▁du', '▁2', '9', '▁décembre', '▁2023', '▁portant', '▁pro', 'mo', 'tion', '▁dans', '▁l', \"'\", 'ord', 're', '▁national', '▁de', '▁la', '▁L', 'é', 'g', 'ion', '▁d', \"'\", 'h', 'onne', 'ur']\n",
      "Avec le corpus 2019-2023 :\n",
      "['▁Décret', '▁du', '▁2', '9', '▁décembre', '▁2023', '▁portant', '▁pro', 'mo', 'tion', '▁dans', '▁l', \"'\", 'ord', 're', '▁national', '▁de', '▁la', '▁L', 'é', 'g', 'ion', '▁d', \"'\", 'h', 'onne', 'ur']\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='./models/1000_tokens.model')\n",
    "print(f\"Avec le corpus 2023 :\")\n",
    "print(sp.EncodeAsPieces(\"Décret du 29 décembre 2023 portant promotion dans l'ordre national de la Légion d'honneur\"))\n",
    "\n",
    "sp = spm.SentencePieceProcessor(model_file='./models/2019_2023.model')\n",
    "print(f\"Avec le corpus 2019-2023 :\")\n",
    "print(sp.EncodeAsPieces(\"Décret du 29 décembre 2023 portant promotion dans l'ordre national de la Légion d'honneur\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec le corpus 2023 :\n",
      "['▁Le', '▁dernier', '▁alinéa', '▁de', '▁l', \"'\", 'article', '▁3', '▁du', '▁décret', '▁du', '▁6', '▁octobre', '▁19', '5', '2', '▁susvisé', '▁est', '▁remplacé', '▁par', '▁un', '▁alinéa', '▁ainsi', '▁rédigé', '▁:', '▁«', '▁Les', '▁militaire', 's', '▁per', 'ç', 'o', 'iv', 'ent', ',', '▁en', '▁ou', 'tre', ',', '▁l', \"'\", 'indemnité', '▁d', \"'\", 'éta', 't', '▁militaire', '▁dans', '▁les', '▁conditions', '▁prévues', '▁par', '▁le', '▁décret', '▁n', '°', '▁5', '9', '-', '11', '9', '3', '▁du', '▁', '13', '▁octobre', '▁19', '5', '9', '▁et', '▁l', \"'\", 'indemnité', '▁de', '▁', 'g', 'ar', 'n', 'is', 'on', '▁des', '▁militaire', 's', '▁prévu', 'e', '▁par', '▁le', '▁décret', '▁n', '°', '▁2023', '-', '3', '9', '8', '▁du', '▁2', '4', '▁mai', '▁2023', '.', '▁»']\n",
      "Avec le corpus 2019-2023 :\n",
      "['▁Le', '▁dernier', '▁alinéa', '▁de', '▁l', \"'\", 'article', '▁3', '▁du', '▁décret', '▁du', '▁6', '▁octobre', '▁19', '5', '2', '▁susvisé', '▁est', '▁remplacé', '▁par', '▁un', '▁alinéa', '▁ainsi', '▁rédigé', '▁:', '▁«', '▁Les', '▁militaire', 's', '▁p', 'er', 'ç', 'o', 'iv', 'ent', ',', '▁en', '▁ou', 'tre', ',', '▁l', \"'\", 'indemnité', '▁d', \"'\", 'état', '▁militaire', '▁dans', '▁les', '▁conditions', '▁prévu', 'es', '▁par', '▁le', '▁décret', '▁n', '°', '▁5', '9', '-1', '19', '3', '▁du', '▁', '13', '▁octobre', '▁19', '5', '9', '▁et', '▁l', \"'\", 'indemnité', '▁de', '▁', 'g', 'ar', 'n', 'is', 'on', '▁des', '▁militaire', 's', '▁prévu', 'e', '▁par', '▁le', '▁décret', '▁n', '°', '▁2023', '-', '3', '9', '8', '▁du', '▁', '24', '▁mai', '▁2023', '.', '▁»']\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='./models/1000_tokens.model')\n",
    "print(f\"Avec le corpus 2023 :\")\n",
    "print(sp.EncodeAsPieces(\"Le dernier alinéa de l'article 3 du décret du 6 octobre 1952 susvisé est remplacé par un alinéa ainsi rédigé : « Les militaires perçoivent, en outre, l'indemnité d'état militaire dans les conditions prévues par le décret n° 59-1193 du 13 octobre 1959 et l'indemnité de garnison des militaires prévue par le décret n° 2023-398 du 24 mai 2023. »\"))\n",
    "\n",
    "sp = spm.SentencePieceProcessor(model_file='./models/2019_2023.model')\n",
    "print(f\"Avec le corpus 2019-2023 :\")\n",
    "print(sp.EncodeAsPieces(\"Le dernier alinéa de l'article 3 du décret du 6 octobre 1952 susvisé est remplacé par un alinéa ainsi rédigé : « Les militaires perçoivent, en outre, l'indemnité d'état militaire dans les conditions prévues par le décret n° 59-1193 du 13 octobre 1959 et l'indemnité de garnison des militaires prévue par le décret n° 2023-398 du 24 mai 2023. »\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec le corpus 2023 :\n",
      "['▁C', 'e', 'ci', '▁est', '▁une', '▁phrase', '▁', 't', 'est', '▁ayant', '▁pour', '▁b', 'ut', '▁de', '▁', 'voir', '▁', 's', 'i', '▁l', \"'\", 'on', '▁par', 'vi', 'ent', '▁à', '▁', 'ob', 'ten', 'ir', '▁des', '▁', 'di', 'ff', 'é', 'r', 'ence', 's', '▁entre', '▁les', '▁deux', '▁', 'mo', 'd', 'è', 'le', 's', '▁', 's', 'i', '▁', 'on', '▁', 'ut', 'ili', 's', 'e', '▁un', '▁champ', '▁l', 'ex', 'ic', 'al', '▁peut', '-', 'ê', 'tre', '▁l', 'é', 'g', 'è', 'r', 'ement', '▁', 'di', 'ff', 'é', 're', 'e', 't', '▁de', '▁ce', '▁dont', '▁les', '▁', 'mo', 'd', 'è', 'le', 's', '▁', 'ont', '▁l', \"'\", 'h', 'ab', 'it', 'u', 'de']\n",
      "Avec le corpus 2019-2023 :\n",
      "['▁C', 'e', 'ci', '▁est', '▁une', '▁phrase', '▁', 'te', 'st', '▁ayant', '▁pour', '▁b', 'ut', '▁de', '▁', 'voir', '▁', 's', 'i', '▁l', \"'\", 'on', '▁par', 'vi', 'ent', '▁à', '▁', 'ob', 'ten', 'ir', '▁des', '▁d', 'if', 'fér', 'ence', 's', '▁entre', '▁les', '▁deux', '▁', 'mo', 'd', 'è', 'le', 's', '▁', 's', 'i', '▁', 'on', '▁', 'ut', 'il', 'is', 'e', '▁un', '▁champ', '▁l', 'ex', 'ic', 'al', '▁peut', '-', 'ê', 'tre', '▁l', 'é', 'g', 'ère', 'ment', '▁d', 'if', 'fér', 'e', 'et', '▁de', '▁ce', '▁dont', '▁les', '▁', 'mo', 'd', 'è', 'le', 's', '▁', 'ont', '▁l', \"'\", 'h', 'ab', 'it', 'u', 'de']\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='./models/1000_tokens.model')\n",
    "print(f\"Avec le corpus 2023 :\")\n",
    "print(sp.EncodeAsPieces(\"Ceci est une phrase test ayant pour but de voir si l'on parvient à obtenir des différences entre les deux modèles si on utilise un champ lexical peut-être légèrement différeet de ce dont les modèles ont l'habitude\"))\n",
    "\n",
    "sp = spm.SentencePieceProcessor(model_file='./models/2019_2023.model')\n",
    "print(f\"Avec le corpus 2019-2023 :\")\n",
    "print(sp.EncodeAsPieces(\"Ceci est une phrase test ayant pour but de voir si l'on parvient à obtenir des différences entre les deux modèles si on utilise un champ lexical peut-être légèrement différeet de ce dont les modèles ont l'habitude\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier corpus a l'air suffisament conséquent pour qu'il n'y ait pas de différences réelles de tokenistation sur le lexique du corpus. Même en dehors de ce lexique, les différences existent mais sont mineures à 1000 tokens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
